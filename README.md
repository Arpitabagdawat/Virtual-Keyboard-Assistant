# ğŸ¯ AI Virtual Keyboard using Hand Gestures

Welcome to my **AI Virtual Keyboard** project â€” an intelligent and interactive keyboard that works completely on **hand gestures** detected through your webcam. ğŸ–ğŸ’»  
No physical typing needed â€” just your hands, camera, and a bit of AI magic! âœ¨  

---

## ğŸš€ Project Overview

This project uses **Computer Vision** and **Artificial Intelligence** to build a **gesture-controlled virtual keyboard** that recognizes your finger positions to simulate key presses.  
Itâ€™s designed to give a **realistic typing experience** and make typing more accessible, futuristic, and fun! ğŸ¤–

---

## ğŸ§© Features Implemented So Far

âœ… **1. Voice Feedback (Text-to-Speech)**  
Every time you press a key, the system *speaks* the letter or key name aloud using `gTTS`.  
> Example: â€œYou pressed Aâ€ ğŸ”Š  

âœ… **2. Full QWERTY Keyboard Layout**  
Includes all standard keys â€” **Aâ€“Z, numbers, Shift, Caps, Space, Enter, and Backspace** for a realistic typing experience.  

âœ… **3. Typing Area with Word Prediction**  
Displays a text box showing typed text with **real-time word prediction** using `nltk`.  
Predicted words appear below the typing area and can be selected by pinching your fingers together.  

âœ… **4. Common Daily Words Prediction**  
The prediction system focuses on **frequently used conversational words** (like *okay, fine, thanks, serious, sure, amazing,* etc.) to make typing more natural and human-like.  

---

## ğŸ§  Technologies & Libraries Used

| Library | Purpose |
|----------|----------|
| `cv2 (OpenCV)` | Hand tracking, button drawing, video feed |
| `cvzone` | Simplified hand detection interface |
| `HandDetector` | Finger position detection |
| `nltk` | Word prediction logic |
| `gTTS` | Text-to-speech (voice feedback) |
| `playsound` | Audio playback |
| `threading` | Smooth non-blocking sound handling |
| `pynput` | Keyboard control (optional) |

---

## âš™ï¸ Installation & Setup

Clone the repository:
```bash
git clone https://github.com/<your-username>/AI-Virtual-Keyboard.git
cd AI-Virtual-Keyboard
```

Install the required dependencies:
```bash
pip install opencv-python cvzone nltk gTTS playsound pynput
```

Download the `nltk` word corpus (only once):
```python
import nltk
nltk.download('words')
```

Run the project:
```bash
python ai_virtual_keyboard.py
```

---

## ğŸ§© How It Works

1. The webcam captures real-time video feed.  
2. The `HandDetector` module tracks hand landmarks and finger positions.  
3. When the index and middle finger come close to a key region â†’ itâ€™s registered as a key press.  
4. Pressed key triggers:  
   - Text appears on screen  
   - Voice feedback plays (using gTTS)  
   - Word predictions update instantly below the text box.  

---

## ğŸ’¡ Future Enhancements

ğŸ”¹ Add support for **multiple languages**  
ğŸ”¹ Include **emoji prediction**  
ğŸ”¹ Save typed text as a `.txt` file  
ğŸ”¹ Add **handwriting recognition mode**  

---

## ğŸ“¸ Demo & Preview

ğŸ¥ *Demo video available on my LinkedIn profile:*  
ğŸ‘‰ [www.linkedin.com/in/arpita-b-66a996292](https://www.linkedin.com/in/arpita-b-66a996292)

---

## ğŸ§‘â€ğŸ’» Author

**Arpita Bagdawat**  
ğŸ“ B.Tech (AI & Data Science) | Mahakal Institute of Technology, Ujjain  
ğŸ’¼ Aspiring Data Scientist & AI Enthusiast  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/arpita-b-66a996292)

---

## ğŸŒŸ Show Your Support

If you like this project, donâ€™t forget to â­ **star the repo** and share your feedback! ğŸ’¬  
Letâ€™s make AI-based interaction more creative and accessible. âœ¨
